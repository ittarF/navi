# Navi

A Python-based autonomous web navigation agent that uses a local LLM via Ollama to control a web browser based on screenshots.

## Overview

Navi is a tool that:
1. Takes screenshots of a browser window
2. Sends them to a local LLM (via Ollama)
3. Parses the LLM's decisions on what actions to take
4. Executes those actions in the browser
5. Repeats until the task is complete

This autonomous agent can handle tasks like searching for information, filling out forms, and navigating through multiple pages.

## Project Structure

The Navi project is organized into these main modules:

- `navi/agent.py` - The NaviAgent class handling browser control and navigation
- `navi/llm.py` - The LLMDecisionMaker class handling interactions with Ollama
- `navi/utils.py` - Utility functions for the agent
- `navi/main.py` - Main CLI entry point

## Requirements

- Python 3.8+
- Ollama installed and running locally
- A compatible LLM model (default: llama3) loaded in Ollama

## Setup

1. Clone this repository:
```bash
git clone https://github.com/ittarF/navi.git
cd navi
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

3. Install browser drivers for Playwright:
```bash
playwright install
```

4. Install Ollama if you haven't already. Follow the instructions at [Ollama's website](https://ollama.ai/).

5. Pull the LLM model you want to use:
```bash
ollama pull llama3
```

## Usage

1. Make sure Ollama is running:
```bash
ollama serve
```

2. Run Navi with a task:
```bash
python navi.py --task "Search for information about climate change on Wikipedia"
```

3. For more options:
```bash
python navi.py --help
```

### Streaming Output

Navi supports real-time streaming of LLM responses, making the experience more interactive and showing how the AI thinks step-by-step:

```bash
python navi.py --task "Search for AI research papers" --stream
```

This displays tokens as they're generated by the LLM, giving you insight into the decision-making process.

### Element Detection

Navi can automatically detect interactive elements on webpages (buttons, links, forms, etc.) and provide them to the LLM, enabling more accurate navigation:

```bash
python navi.py --task "Sign up for a newsletter" --max-elements 30
```

This feature:
- Identifies clickable elements, input fields, and other interactive controls
- Ranks elements by importance and visibility
- Provides the LLM with a numbered list of available elements
- Allows the LLM to reference elements by number instead of coordinates

To disable element detection:
```bash
python navi.py --task "Search for something" --no-element-detection
```

## Examples

Check out the examples directory for sample scripts:

- `examples/search_task.py` - Example of a simple search task
- `examples/form_task.py` - Example of filling out a form
- `examples/describe_page.py` - Example of capturing a screenshot and describing a webpage

To run an example:
```bash
python examples/describe_page.py https://example.com
```

With streaming output:
```bash
python examples/describe_page.py https://example.com --stream
```

## Customization

You can modify these parameters in `config.py` or set them using environment variables:
- `HEADLESS`: Set to `True` to run without showing the browser window
- `MODEL_NAME`: Change to use a different Ollama model
- `OLLAMA_BASE_URL`: Change if Ollama is running on a different host or port

## Example Tasks

Navi can handle tasks like:
- "Search for information about climate change on Wikipedia"
- "Go to example.com and fill out the contact form"
- "Find the price of Product X on Amazon"
- "Find the latest news about artificial intelligence"

## How It Works

Navi operates in a loop:
1. Takes a screenshot of the current browser view
2. Detects interactive elements on the page (buttons, links, forms)
3. Sends the screenshot and element list to the LLM
4. The LLM decides what action to take (click, type, navigate, scroll, etc.)
5. The agent executes that action
6. This process repeats until the task is complete or a maximum number of steps is reached

## Performance Optimization

Navi includes options to optimize LLM performance:

1. **Concise Outputs**: The system is configured to encourage brief, to-the-point responses from the LLM.

2. **Streaming**: Enable real-time token streaming to see responses as they're generated with the `--stream` flag.

3. **Response Limits**: Output length is constrained to focus on essential information only.

4. **Element Detection**: By detecting interactive elements, the LLM can make more informed decisions without relying solely on image recognition.

## Troubleshooting

- If you see connection errors, make sure Ollama is running
- If the agent fails to find elements, try adjusting the browser window size
- If the LLM makes poor decisions, you may need a more capable model

## License

MIT